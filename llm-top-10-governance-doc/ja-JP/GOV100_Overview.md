## 第一章　概要

すべてのインターネットユーザーと企業は、来るべき強力な生成的人工知能（生成AI）アプリケーションの波に備えなければなりません。生成AIは、様々な業界に、革新と効率化、商業的成功をもたらす大きな可能性を秘めている一方、他の強力な初期段階のテクノロジーと同様、予期せぬ、新たな課題ももたらすからです。

人工知能は、過去50年間大きく発展し、目立たないかたちで、企業の様々なプロセスをゆるやかにサポートしてきましたが、ChatGPTの登場により、個人のレベル、並びに企業の間で、大規模言語モデル(LLM)の開発と利用が推し進められることとなりました。　当初、これらのテクノロジーは、学術的な研究や、企業内の特定の、しかし重要な活動の実行に限定され、一部の人にしか見えませんでした。しかし、データの可用性、コンピュータの能力、生成AIの能力、そしてLlama 2、ElevenLabs、Midjourneyのようなツールのリリースにおける最近の進歩は、AIをニッチなものから一般的に広く受け入れられるものへと引き上げました。これらの改善は、生成AI技術をより身近なものにしただけでなく、企業が業務にAIを統合し、活用するための確固たる戦略を開発する必要性を浮き彫りにし、テクノロジーの利用方法における大きな前進を表しています。

  - 人工知能(AI)は、通常人間の知能を必要とするタスクを機械が達成できるようにするコンピュータサイエンスのすべての分野を包含する広い用語です。機械学習と生成AIはAIの2つのサブカテゴリーです。
  - 機械学習はAIのサブセットで、データから学習できるアルゴリズムの作成に重点を置いています。機械学習アルゴリズムは一連のデータで学習され、そのデータを使って新しいデータの予測や意思決定を行うことができます。
  - 生成AIは、新しいデータの作成に焦点を当てた機械学習の一種です。
  - 大規模言語モデル（LLM）は、人間のようなテキストを処理して生成するAIモデルの一種です。人工知能の文脈で「モデル」とは、入力データに基づいて予測を行うように訓練されたシステムを指します。LLMは特に自然言語の大規模なデータセットで学習されるため、大規模言語モデルと呼ばれています。

組織は生成AIソリューションのセキュリティ確保と監督において未知の領域に突入しています。生成AIの急速な進歩は、敵対者が攻撃戦略を強化する門戸も開き、防御と脅威の拡大という二重の課題をもたらします。

企業は、採用のための人事、電子メールのスパムスクリーニング、行動分析のためのSIEM、管理された検出と応答のアプリケーションなど、多くの分野で人工知能を使用しています。しかし、このドキュメントの主な焦点は、大規模言語モデルのアプリケーションと、 生成されたコンテンツを作成する機能です。

### 責任ある信頼できる人工知能

人工知能の課題と利点が明らかになり、規制や法律が成立するにつれ、責任ある信頼できる AI 利用の原則と柱は、理想主義的な対象や懸念から確立された基準へと進化しています。OWASP AI Exchange ワーキンググループは、このような変化を監視し、人工知能のあらゆる側面における、より広範でより困難な考慮事項に取り組んでいます。

>||center|16|16 信頼できる AI の条件

    >indianred|white|left|14|18 確実性（reliable）
    >indianred|white|left|12|16 　　　　強靭であること（robust）
    >indianred|white|left|12|16 　　　　責任の所在が明らかなこと（accountable）
    >indianred|white|left|12|16 　　　　常に確認していること（monitored）
    >indianred|white|left|12|16 　　　　透明性があること（transparent）
    >indianred|white|left|12|16 　　　　なぜかを説明できること（explainable）

    >forestgreen|white|left|14|18 安全性（resilience）
    >forestgreen|white|left|12|16 　　　　安全であること（safe）
    >forestgreen|white|left|12|16 　　　　安心できること（secure）
    >forestgreen|white|left|12|16 　　　　個人情報が守られていること（private）
    >forestgreen|white|left|12|16 　　　　効果的であること（effective）

    >dodgerblue|white|left|14|18 道義性（responsible）
    >dodgerblue|white|left|12|16 　　　　公正であること（fair）
    >dodgerblue|white|left|12|16 　　　　道徳的に正しいこと（ethical）
    >dodgerblue|white|left|12|16 　　　　一部の人をのけ者にしないこと（inclusive）
    >dodgerblue|white|left|12|16 　　　　持続可能なこと（sustainable）
    >dodgerblue|white|left|12|16 　　　　はっきりした目的があること（purposeful）

##### 図 1.1　信頼できる AI の条件

### 対象読者

OWASP 大規模言語モデル アプリケーション リスク トップ10 サイバーセキュリティとガバナンスのチェックリストは、経営幹部、技術者、サイバーセキュリティ、プライバシー、コンプライアンス、法務、DevSecOps、MLSecOps、サイバーセキュリティチーム、および守備担当者の各分野のリーダーを対象としています。AIを企業の成功に活用するだけでなく、性急で安全でないAIの実装によるリスクからも保護することを目指し、急速に変化するAIの世界で一歩先を行く努力をしている人々を対象としています。こうしたリーダーやチームは、チャンスをつかみ、課題と戦い、リスクを軽減するための戦術を構築しなければなりません。

このチェックリストは、技術およびビジネスリーダーがLLMを使用するリスクとメリットを迅速に理解し、大規模言語モデル戦略を策定する際に、組織を防御し保護するために必要な重要な領域とタスクの包括的なリストの作成に集中できるようにすることを目的としています。

OWASP 大規模言語モデル アプリケーション リスク トップ10 チームは、このリストが組織の既存の防御テクニックの改善や、このエキサイティングなテクノロジーを使用することで新たに発生する脅威（ ）に対処するテクニックの開発に役立つことを願っています。

### なぜチェックリストが必要なのか

戦略を策定するために使用されるチェックリストは、正確性を向上させ、目的を明確にし、統一性を保ち、集中した慎重な作業を促し、見落としや細部の見逃しを減らします。チェックリストに従うことは、安全な採用の旅への信頼を高めるだけでなく、継続的な改善のためのシンプルで効果的な戦略を提供することで、将来の組織の革新を促します。

### 包括的ではない

本文書は、急速に変化する技術的、法的、及び規制的環境において、組織が初期のLLM戦略を策定する際の支援を意図していますが、網羅的なものではなく、全てのユースケースや義務を網羅するものではあり ません。組織は、この文書を使用する一方で、提供されたチェックリストの範囲を超えて、その使用 ケース又は管轄区域の必要に応じて、評価及び実務を拡張する必要があります。

### 大規模言語モデルの課題

大規模な言語モデルは、いくつかの深刻で独特な問題に直面しています。最も重要なことの1つは、LLMで作業している間、制御プレーンとデータプレーンを厳密に分離または分離することができないということです。もう1つの重大な課題は、LLMは設計上非決定論的であり、促したり要求したりすると異なる結果をもたらすことです。LLMはキーワード検索ではなくセマンティック検索を採用しています。この2つの重要な違いは、モデルのアルゴリズムがレスポンスに含まれる用語に優先順位をつけることです。これは消費者がこれまでテクノロジーを使ってきた方法とは大きく異なり、結果の一貫性と信頼性に影響を与えます。幻覚は、モデルがトレーニングされたデータのギャップやトレーニングの欠陥から生じるもので、この方法の結果です。

信頼性を向上させ、ジェイルブレイク、モデルトリック、幻覚に対する攻撃面を減らす方法はありますが、コストと機能の両方において、制限と実用性の間にトレードオフがあります。

LLM の使用と LLM アプリケーションは、組織の攻撃対象領域を拡大します。関連するリスク
 
LLMはユニークですが、既知のソフトウェア部品表（SBoM）、サプライチェーン、データ損失保護（DLP）、認証されたアクセスなど、多くはおなじみの問題です。また、生成AIとは直接関係のないリスクの増加もありますが、生成AIは組織を攻撃し脅かす攻撃者の効率性、能力、有効性を高めます。

LLM とジェネレーティブ AI ツールを活用し、組織、個人、政府システムを攻撃する従来の手法を見直し、迅速化する動きが加速しています。LLMは、新しいゼロデイ脆弱性を埋め込んだり、検知を回避するように設計された新しいマルウェアを簡単に作成できるようにするテクニックを強化する能力を促進します。また、洗練されたユニークなフィッシング詐欺の手口を生み出すことも可能です。動画や音声を使った説得力のあるフェイクを作成することで、ソーシャルエンジニアリングの策略をさらに促進します。さらに、これらのツールは、侵入を実行し、革新的なハッキング能力を開発することを可能にします。今後、犯罪行為者によるAI技術の「テーラーメイド」かつ複合的な利用が進むにつれ、組織の適切な防御・回復能力に対する特別な対応や専用ソリューションが求められるようになるでしょう。

組織はまた、競争上の不利、顧客やパートナーからの時代遅れという市場認識、パーソナライズされたコミュニケーションの拡張不能、イノベーションの停滞、運用上の不備、プロセスにおける人為的ミスのリスクの増大、人的資源の不適切な配分など、LLMの能力を活用できない脅威にも直面しています。

さまざまな種類の脅威を理解し、ビジネス戦略と統合することで、大規模言語モデル（LLM）を使用するメリットとデメリットを比較検討することができます。 、ビジネス目標の達成を妨げるのではなく、むしろ加速させることができます。

### AI の脅威

>||center|16|16 AI の脅威の分類

    >gray|white|left|14|18 AI モデルを使わないことによる脅威
    >gray|white|left|14|18 AI 法的な規制による脅威
    >gray|white|left|14|18 AI モデルを使うことによる脅威
    >gray|white|left|14|18 AI モデルが狙われることによる脅威
    >gray|white|left|14|18 AI モデルが生み出す脅威

##### 図 1.2　AIの脅威の分類

### 人工知能のセキュリティとプライバシーのトレーニング

人工知能（AI）、生成AI、LLMの構築、購入、利用が将来もたらす可能性のある結果を理解するためのトレーニングは、組織全体の従業員にとって有益です。許容される使用とセキュリティ意識に関するトレーニングは、すべての従業員を対象とするだけでなく、人事部、法務部、開発者、データチーム、セキュリティチームなど、特定の職種に特化したものであるべきです。

公正使用ポリシーと健全な相互作用は、最初から組み込まれていれば、将来のAIサイバーセキュリティ啓発キャンペーンの成功の礎となる重要な側面です。これにより、ユーザーには対話のための基本的なルールの知識だけでなく、 、良い行動と悪い行動や非倫理的な行動を区別する能力が提供されることになります。

### LLMのセキュリティとガバナンスを既存の確立された実務と
### 統制に組み込むこと

AIと生成されたAIは、サイバーセキュリティ、回復力、プライバシー、法的・規制的要件への対応に新たな局面をもたらしますが、問題を特定し、脆弱性を発見し、脆弱性を修正し、潜在的なセキュリティ問題を軽減するには、以前からあるベストプラクティスが依然として最善の方法です。

  - 人工知能システムの管理が既存の組織慣行と統合されていることを確認します。
  - AI ML システムが既存のプライバシー、ガバナンス、およびセキュリティ慣行に従うことを確認し、AI が要求する場合には、特定のプライバシー、ガバナンス、およびセキュリティ慣行を実施します。

### セキュリティの基本原則

LLM の機能は、異なるタイプの攻撃と攻撃対象領域をもたらします。LLMは、プロンプト・インジェクション、安全でないプラグイン設計、リモート・コード実行などの複雑なビジネス・ロジックのバグに対して脆弱です。これらの問題を解決するには、既存のベストプラクティスが最適です。セキュアなソフトウェアのレビュー、アーキテクチャ、データガバナンス、サードパーティの評価を理解している社内の製品セキュリティチーム サイバーセキュリティチームは、音声クローニング、なりすまし、キャプチャのバイパスなど、LLMによって悪化する可能性のある問題を見つけるために、現在のコントロールがどの程度強力であるかもチェックする必要があります。機械学習、NLP（自然言語処理）、NLU（自然言語理解）、ディープラーニング、そして最近ではLLM（大規模言語モデル）やジェネレーティブAIの最近の進歩を考慮すると、サイバーセキュリティとデブオプスのチームと一緒にこれらの分野に精通した専門家を含めることをお勧めします。彼らの専門知識は、これらの技術を採用するだけでなく、新たな課題に対する革新的な分析や対応を開発する上でも役立ちます。

### リスク

リスクに関する言及はISO31000の定義を使用：リスク＝「目的に対する不確実性の影響」。チェックリストに含まれるLLMリスクには、敵対的リスク、安全リスク、 法務リスク、規制リスク、レピュテーションリスク、財務リスク、競争リスクに対応するLLMリスクのターゲットリストが含まれます。

### 脆弱性と緩和の分類法

OVAL、STIX、CVE、CWEなど、脆弱性を分類し脅威情報を共有するための現在のシステムは、大規模言語モデル（LLM）や予測モデルに固有の脆弱性や脅威を監視し、防御者に警告する機能を開発中です。AI/MLシステムとそのサプライチェーンに対する脆弱性や脅威が特定された場合、組織は脆弱性分類のためのCVEやサイバー脅威インテリジェンス（CTI）の交換のためのSTIXのような、確立され認知されたこれらの標準に依存することが予想されます。
